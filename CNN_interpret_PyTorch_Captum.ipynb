{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN-interpret-PyTorch_Captum.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THC9wL57HCBS",
        "outputId": "2162f662-7a7f-490d-9aaa-f5b786b4d0b0"
      },
      "source": [
        "!pip install captum"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting captum\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/b0/8fa3ab89e2e37c960cdd09595fa911fbb8d6da216c8bc98e18c858a0128d/captum-0.3.1-py3-none-any.whl (4.4MB)\n",
            "\u001b[K     |████████████████████████████████| 4.4MB 22.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.2 in /usr/local/lib/python3.7/dist-packages (from captum) (1.8.1+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from captum) (1.19.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from captum) (3.2.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.2->captum) (3.7.4.3)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->captum) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->captum) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->captum) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->captum) (0.10.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->captum) (1.15.0)\n",
            "Installing collected packages: captum\n",
            "Successfully installed captum-0.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sre9ZofuG6HZ"
      },
      "source": [
        "import captum\n",
        "\n",
        "import spacy\n",
        "\n",
        "import torch\n",
        "import torchtext\n",
        "import torchtext.data\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchtext.legacy.data import BucketIterator\n",
        "from torchtext.vocab import GloVe\n",
        "from torchtext.legacy.data import Field, LabelField\n",
        "from torchtext.legacy.datasets import SST\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "from torchtext.vocab import Vocab\n",
        "\n",
        "from captum.attr import LayerIntegratedGradients, TokenReferenceBase, visualization, LayerDeepLift, LayerConductance, LayerFeatureAblation, DeepLift, Deconvolution\n",
        "\n",
        "nlp = spacy.load('en')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjSnUxwfHI0q"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LrsK_0EAwO3"
      },
      "source": [
        "def preprocess_labels(score):\n",
        "  print(score)\n",
        "  if score >= 0 and score < 0.2:\n",
        "      label = 0\n",
        "  elif score >= 0.2 and score < 0.4:\n",
        "      label = 1\n",
        "  elif score >= 0.4 and score < 0.6:\n",
        "      label = 2\n",
        "  elif score >=0.6 and score < 0.8:\n",
        "      label = 3\n",
        "  else:\n",
        "      label = 4\n",
        "  return label "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPP3jO0MQ7nN"
      },
      "source": [
        "def get_sst_data(device):\n",
        "    # set up fields\n",
        "    #TEXT = Field(lower=True, include_lengths=True, batch_first=True)\n",
        "    #LABEL =Field(sequential=False)\n",
        "    TEXT = Field(lower=True, tokenize='spacy', batch_first=True)\n",
        "    Label = LabelField(dtype = torch.float, use_vocab=True, preprocessing=float)\n",
        "\n",
        "\n",
        "    # make splits for data\n",
        "    train, val, test = SST.splits(TEXT, Label, fine_grained=True)\n",
        "\n",
        "    # build the vocabulary\n",
        "    loaded_vectors = GloVe(name='6B', dim=100)\n",
        "    loaded_vectors = torchtext.vocab.Vectors('glove.6B.100d.txt')\n",
        "    TEXT.build_vocab(train, vectors=loaded_vectors, max_size=len(loaded_vectors.stoi))\n",
        "    TEXT.vocab.set_vectors(stoi=loaded_vectors.stoi, vectors=loaded_vectors.vectors, dim=loaded_vectors.dim)\n",
        "\n",
        "    Label.build_vocab(train)\n",
        "    text_vocab = TEXT.vocab\n",
        "    x = torch.tensor(1)\n",
        "\n",
        "    # make iterator for splits\n",
        "    train_iter, val_iter, test_iter = BucketIterator.splits(\n",
        "        (train, val, test), batch_size=32, device=torch.device('cuda:0')) # for CPU, device = -1\n",
        "\n",
        "    return train_iter, val_iter, test_iter, text_vocab, TEXT, Label"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXeP03JLRHSM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53add143-bf1d-463a-9069-de0582c3ede4"
      },
      "source": [
        "train_iter, val_iter, test_iter, vocab, TEXT, Label = get_sst_data(device)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downloading trainDevTestTrees_PTB.zip\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "trainDevTestTrees_PTB.zip: 100%|██████████| 790k/790k [00:00<00:00, 935kB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "extracting\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [02:41, 5.33MB/s]                           \n",
            "100%|█████████▉| 399289/400000 [00:14<00:00, 26868.42it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nopScTJ-HS02"
      },
      "source": [
        "class TextCNN(nn.Module):\n",
        "    def __init__(self, vocab,  embedding_dim, n_filters, num_classes, dropout, pad_idx = 0, window_sizes=(1,2,3,5)):\n",
        "        super(TextCNN, self).__init__()\n",
        "        # load pretrained embedding in embedding layer.\n",
        "        self.embedding = nn.Embedding(len(vocab), embedding_dim, padding_idx = pad_idx)\n",
        "        #self.embedding.weight.data.copy_(vocab.vectors)\n",
        "\n",
        "        self.convs = nn.ModuleList([\n",
        "            nn.Conv2d(in_channels=1, out_channels=n_filters, kernel_size=(window_size, embedding_dim), padding=(window_size - 1, 0))\n",
        "            for window_size in window_sizes\n",
        "        ])\n",
        "\n",
        "        self.fc = nn.Linear(n_filters * len(window_sizes), num_classes)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, text, max_sent_len=49):\n",
        "        #text_emb = text_emb.unsqueeze(1).unsqueeze(2)\n",
        "        #text_emb = text_emb.expand(-1,1,max_sent_len,-1).to(device)\n",
        "\n",
        "        #text = [batch size, sent len]\n",
        "        \n",
        "        text_emb = self.embedding(text)\n",
        "\n",
        "        # text_emb = [batch size, sent len, emb dim]\n",
        "\n",
        "        text_emb = text_emb.unsqueeze(1)\n",
        "\n",
        "        # text_emb = [batch size, 1, sent len, emb dim]\n",
        "\n",
        "        conved = [F.relu(conv(text_emb)).squeeze(3) for conv in self.convs]\n",
        "        # conv_n = [batch size, n_filters, sent len - filter_sizes[n]]\n",
        "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
        "        # pooled_n = [batch size, n_filters]\n",
        "        cat = self.dropout(torch.cat(pooled, dim=1))\n",
        "        # cat = [batch size, n_filters * len(filter_sizes)]\n",
        "        return self.fc(cat)\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fG5V532cH1Ty"
      },
      "source": [
        "model = TextCNN(vocab, embedding_dim=100, n_filters=100, num_classes=5, dropout=0.5, window_sizes=(3,), pad_idx=0)\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kPDmA6mICYP"
      },
      "source": [
        "def forward_with_sigmoid(input):\n",
        "    return torch.sigmoid(model(input))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ab0-SUtc-QEf",
        "outputId": "8587437e-f990-40cc-9075-d76fbee5bf90"
      },
      "source": [
        "for key in Label.vocab.freqs:\n",
        "  print(key, Label.vocab.stoi[key])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "positive 0\n",
            "very positive 3\n",
            "neutral 2\n",
            "negative 1\n",
            "very negative 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Cm9MqBuKAXq"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion, device):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    model.train() # sets the training mode\n",
        "\n",
        "    for batch in iterator:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        predictions = model(batch.text)\n",
        "        true_labels = batch.label.long()\n",
        "      \n",
        "        #true_labels = torch.sub(batch.label, torch.tensor(1))\n",
        "        #true_labels = true_labels.to(device)\n",
        "\n",
        "        # Calc loss\n",
        "        loss = criterion(predictions, true_labels)\n",
        "        acc = categorical_accuracy(predictions, true_labels)\n",
        "\n",
        "        # Calcualte train and validation losses after 10 episodes\n",
        "        # Backprop step\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_acc/len(iterator), model\n",
        "\n",
        "\n",
        "def evaluate(model, iterator, criterion, device, split='val'):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    model.eval()\n",
        "    #num_iterations = 0\n",
        "    with torch.no_grad():\n",
        "        #for emb, labels in get_batched_emb_labels(args, split=split):\n",
        "        for batch in iterator:\n",
        "            predictions = model(batch.text)\n",
        "            true_labels = batch.label.long()\n",
        "            \n",
        "            #true_labels = torch.sub(batch.label, torch.tensor(1))\n",
        "            \n",
        "            #true_labels = true_labels.to(device)\n",
        "\n",
        "            loss = criterion(predictions, true_labels)\n",
        "            acc = categorical_accuracy(predictions, true_labels)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "            #num_iterations += 1\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RoS0vhBBX9DJ",
        "outputId": "ca37680a-3154-4f13-90cd-3029e8c89558"
      },
      "source": [
        "print('Vocabulary Size: ', len(TEXT.vocab))\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary Size:  15480\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdZYSVyFYNii"
      },
      "source": [
        "PAD_IND = TEXT.vocab.stoi['pad']\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDmM6wRhJdBM",
        "outputId": "6d4c4f8f-ed32-430d-8a64-d0ed4656baa9"
      },
      "source": [
        "PAD_IND"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12760"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2sqw4RoLUkW"
      },
      "source": [
        "def categorical_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    We calculate the accuracy by performing an argmax to get the index of the maximum value in the prediction for\n",
        "    each element in the batch, and then counting how many times this equals the actual label.\n",
        "    We then average this across the batch.\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "    top_pred = preds.argmax(1, keepdim = True)\n",
        "    correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
        "    acc = correct.float() / y.shape[0]\n",
        "    return acc"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfY6ofFoJfyo",
        "outputId": "098c0ed4-06f5-41dc-f85a-2f38656fdd2c"
      },
      "source": [
        "model = model.to(\"cuda:0\")\n",
        "optimizer = optim.Adam(model.parameters(), lr=float(1e-4))\n",
        "loss_fn = nn.CrossEntropyLoss()  # nn.NLLLoss()\n",
        "# CrossEntropyLoss expects the input to be [batch size, n classes] and the label to be [batch size].\n",
        "loss_fn.to(device)\n",
        "\n",
        "#SST.iters(batch_size=32, device=None) # change device to -1 if using cpu\n",
        "\n",
        "for epoch in range(50):\n",
        "\n",
        "    train_loss, train_acc, model = train(model, train_iter, optimizer, loss_fn, device)\n",
        "    # calculate validation loss and accuracy\n",
        "    valid_loss, valid_acc = evaluate(model, val_iter, loss_fn, device, split='val')\n",
        "\n",
        "    print(f'Epoch: {epoch + 1} ')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc * 100:.2f}%')\n",
        "torch.save(model.state_dict(), f\"cnn_model_50.pt\")\n",
        "\n",
        "test_loss, test_acc = evaluate(model, test_iter, loss_fn, device, split='test')\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r100%|█████████▉| 399289/400000 [00:29<00:00, 26868.42it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 \n",
            "\tTrain Loss: 1.711 | Train Acc: 22.67%\n",
            "\t Val. Loss: 1.567 |  Val. Acc: 29.32%\n",
            "Epoch: 2 \n",
            "\tTrain Loss: 1.642 | Train Acc: 25.50%\n",
            "\t Val. Loss: 1.558 |  Val. Acc: 30.57%\n",
            "Epoch: 3 \n",
            "\tTrain Loss: 1.621 | Train Acc: 26.45%\n",
            "\t Val. Loss: 1.552 |  Val. Acc: 31.46%\n",
            "Epoch: 4 \n",
            "\tTrain Loss: 1.589 | Train Acc: 27.81%\n",
            "\t Val. Loss: 1.547 |  Val. Acc: 32.66%\n",
            "Epoch: 5 \n",
            "\tTrain Loss: 1.561 | Train Acc: 29.81%\n",
            "\t Val. Loss: 1.543 |  Val. Acc: 31.82%\n",
            "Epoch: 6 \n",
            "\tTrain Loss: 1.551 | Train Acc: 30.37%\n",
            "\t Val. Loss: 1.537 |  Val. Acc: 32.18%\n",
            "Epoch: 7 \n",
            "\tTrain Loss: 1.543 | Train Acc: 30.61%\n",
            "\t Val. Loss: 1.535 |  Val. Acc: 32.53%\n",
            "Epoch: 8 \n",
            "\tTrain Loss: 1.535 | Train Acc: 31.17%\n",
            "\t Val. Loss: 1.528 |  Val. Acc: 32.98%\n",
            "Epoch: 9 \n",
            "\tTrain Loss: 1.512 | Train Acc: 32.90%\n",
            "\t Val. Loss: 1.525 |  Val. Acc: 33.07%\n",
            "Epoch: 10 \n",
            "\tTrain Loss: 1.503 | Train Acc: 34.02%\n",
            "\t Val. Loss: 1.522 |  Val. Acc: 33.16%\n",
            "Epoch: 11 \n",
            "\tTrain Loss: 1.495 | Train Acc: 34.42%\n",
            "\t Val. Loss: 1.517 |  Val. Acc: 33.78%\n",
            "Epoch: 12 \n",
            "\tTrain Loss: 1.488 | Train Acc: 34.67%\n",
            "\t Val. Loss: 1.514 |  Val. Acc: 33.70%\n",
            "Epoch: 13 \n",
            "\tTrain Loss: 1.468 | Train Acc: 36.24%\n",
            "\t Val. Loss: 1.510 |  Val. Acc: 34.59%\n",
            "Epoch: 14 \n",
            "\tTrain Loss: 1.466 | Train Acc: 36.63%\n",
            "\t Val. Loss: 1.507 |  Val. Acc: 34.23%\n",
            "Epoch: 15 \n",
            "\tTrain Loss: 1.464 | Train Acc: 36.07%\n",
            "\t Val. Loss: 1.503 |  Val. Acc: 35.12%\n",
            "Epoch: 16 \n",
            "\tTrain Loss: 1.447 | Train Acc: 37.07%\n",
            "\t Val. Loss: 1.501 |  Val. Acc: 34.59%\n",
            "Epoch: 17 \n",
            "\tTrain Loss: 1.437 | Train Acc: 38.40%\n",
            "\t Val. Loss: 1.497 |  Val. Acc: 34.32%\n",
            "Epoch: 18 \n",
            "\tTrain Loss: 1.425 | Train Acc: 39.35%\n",
            "\t Val. Loss: 1.493 |  Val. Acc: 35.75%\n",
            "Epoch: 19 \n",
            "\tTrain Loss: 1.418 | Train Acc: 39.62%\n",
            "\t Val. Loss: 1.489 |  Val. Acc: 35.12%\n",
            "Epoch: 20 \n",
            "\tTrain Loss: 1.414 | Train Acc: 39.55%\n",
            "\t Val. Loss: 1.485 |  Val. Acc: 35.66%\n",
            "Epoch: 21 \n",
            "\tTrain Loss: 1.403 | Train Acc: 40.82%\n",
            "\t Val. Loss: 1.483 |  Val. Acc: 36.02%\n",
            "Epoch: 22 \n",
            "\tTrain Loss: 1.392 | Train Acc: 41.53%\n",
            "\t Val. Loss: 1.478 |  Val. Acc: 35.75%\n",
            "Epoch: 23 \n",
            "\tTrain Loss: 1.378 | Train Acc: 41.75%\n",
            "\t Val. Loss: 1.474 |  Val. Acc: 35.48%\n",
            "Epoch: 24 \n",
            "\tTrain Loss: 1.370 | Train Acc: 42.45%\n",
            "\t Val. Loss: 1.471 |  Val. Acc: 35.84%\n",
            "Epoch: 25 \n",
            "\tTrain Loss: 1.369 | Train Acc: 43.13%\n",
            "\t Val. Loss: 1.469 |  Val. Acc: 35.93%\n",
            "Epoch: 26 \n",
            "\tTrain Loss: 1.354 | Train Acc: 43.62%\n",
            "\t Val. Loss: 1.464 |  Val. Acc: 35.21%\n",
            "Epoch: 27 \n",
            "\tTrain Loss: 1.341 | Train Acc: 43.83%\n",
            "\t Val. Loss: 1.461 |  Val. Acc: 36.46%\n",
            "Epoch: 28 \n",
            "\tTrain Loss: 1.337 | Train Acc: 44.14%\n",
            "\t Val. Loss: 1.457 |  Val. Acc: 35.97%\n",
            "Epoch: 29 \n",
            "\tTrain Loss: 1.327 | Train Acc: 45.21%\n",
            "\t Val. Loss: 1.454 |  Val. Acc: 35.93%\n",
            "Epoch: 30 \n",
            "\tTrain Loss: 1.322 | Train Acc: 45.62%\n",
            "\t Val. Loss: 1.450 |  Val. Acc: 36.46%\n",
            "Epoch: 31 \n",
            "\tTrain Loss: 1.308 | Train Acc: 46.31%\n",
            "\t Val. Loss: 1.447 |  Val. Acc: 37.18%\n",
            "Epoch: 32 \n",
            "\tTrain Loss: 1.289 | Train Acc: 47.30%\n",
            "\t Val. Loss: 1.445 |  Val. Acc: 36.73%\n",
            "Epoch: 33 \n",
            "\tTrain Loss: 1.287 | Train Acc: 47.75%\n",
            "\t Val. Loss: 1.441 |  Val. Acc: 37.31%\n",
            "Epoch: 34 \n",
            "\tTrain Loss: 1.277 | Train Acc: 47.81%\n",
            "\t Val. Loss: 1.438 |  Val. Acc: 36.87%\n",
            "Epoch: 35 \n",
            "\tTrain Loss: 1.273 | Train Acc: 47.83%\n",
            "\t Val. Loss: 1.435 |  Val. Acc: 37.05%\n",
            "Epoch: 36 \n",
            "\tTrain Loss: 1.256 | Train Acc: 48.78%\n",
            "\t Val. Loss: 1.434 |  Val. Acc: 36.24%\n",
            "Epoch: 37 \n",
            "\tTrain Loss: 1.251 | Train Acc: 49.49%\n",
            "\t Val. Loss: 1.432 |  Val. Acc: 37.05%\n",
            "Epoch: 38 \n",
            "\tTrain Loss: 1.239 | Train Acc: 49.80%\n",
            "\t Val. Loss: 1.430 |  Val. Acc: 37.76%\n",
            "Epoch: 39 \n",
            "\tTrain Loss: 1.236 | Train Acc: 50.21%\n",
            "\t Val. Loss: 1.427 |  Val. Acc: 37.53%\n",
            "Epoch: 40 \n",
            "\tTrain Loss: 1.219 | Train Acc: 51.56%\n",
            "\t Val. Loss: 1.425 |  Val. Acc: 38.03%\n",
            "Epoch: 41 \n",
            "\tTrain Loss: 1.214 | Train Acc: 50.62%\n",
            "\t Val. Loss: 1.424 |  Val. Acc: 37.49%\n",
            "Epoch: 42 \n",
            "\tTrain Loss: 1.203 | Train Acc: 51.97%\n",
            "\t Val. Loss: 1.423 |  Val. Acc: 37.80%\n",
            "Epoch: 43 \n",
            "\tTrain Loss: 1.192 | Train Acc: 52.39%\n",
            "\t Val. Loss: 1.420 |  Val. Acc: 36.96%\n",
            "Epoch: 44 \n",
            "\tTrain Loss: 1.177 | Train Acc: 52.65%\n",
            "\t Val. Loss: 1.419 |  Val. Acc: 37.71%\n",
            "Epoch: 45 \n",
            "\tTrain Loss: 1.174 | Train Acc: 52.90%\n",
            "\t Val. Loss: 1.418 |  Val. Acc: 37.45%\n",
            "Epoch: 46 \n",
            "\tTrain Loss: 1.164 | Train Acc: 53.56%\n",
            "\t Val. Loss: 1.416 |  Val. Acc: 37.89%\n",
            "Epoch: 47 \n",
            "\tTrain Loss: 1.146 | Train Acc: 54.75%\n",
            "\t Val. Loss: 1.414 |  Val. Acc: 37.80%\n",
            "Epoch: 48 \n",
            "\tTrain Loss: 1.143 | Train Acc: 53.76%\n",
            "\t Val. Loss: 1.414 |  Val. Acc: 37.71%\n",
            "Epoch: 49 \n",
            "\tTrain Loss: 1.132 | Train Acc: 55.65%\n",
            "\t Val. Loss: 1.413 |  Val. Acc: 37.89%\n",
            "Epoch: 50 \n",
            "\tTrain Loss: 1.119 | Train Acc: 55.00%\n",
            "\t Val. Loss: 1.410 |  Val. Acc: 37.89%\n",
            "Test Loss: 1.419 | Test Acc: 37.95%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIWE8cxbiZgI",
        "outputId": "97b2a4e8-becb-449d-add9-a922e789560d"
      },
      "source": [
        "torch.load('cnn_model_50.pt')\n",
        "model.eval()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TextCNN(\n",
              "  (embedding): Embedding(15480, 100, padding_idx=0)\n",
              "  (convs): ModuleList(\n",
              "    (0): Conv2d(1, 100, kernel_size=(3, 100), stride=(1, 1), padding=(2, 0))\n",
              "  )\n",
              "  (fc): Linear(in_features=100, out_features=5, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3gGdDPkY_dP"
      },
      "source": [
        "token_reference = TokenReferenceBase(reference_token_idx=PAD_IND)\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EG-fY7p8ZHIH"
      },
      "source": [
        "lig = LayerIntegratedGradients(model, model.embedding)\n",
        "#lig = LayerIntegratedGradients(model, model.convs)\n",
        "dl = DeepLift(model)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITd_w9f7aMpl"
      },
      "source": [
        "# accumalate couple samples in this array for visualization purposes\n",
        "vis_data_records_ig = []\n",
        "\n",
        "def interpret_sentence(model, sentence, min_len = 30, true_label = 0):\n",
        "    text = [tok.text for tok in nlp.tokenizer(sentence.lower())]\n",
        "    if len(text) < min_len:\n",
        "        text += ['pad'] * (min_len - len(text))\n",
        "    indexed = [TEXT.vocab.stoi[t] for t in text]\n",
        "\n",
        "    model.zero_grad()\n",
        "\n",
        "    input_indices = torch.tensor(indexed, device=device)\n",
        "    input_indices = input_indices.unsqueeze(0)\n",
        "\n",
        "    #print(input_indices.shape)\n",
        "    \n",
        "    # input_indices dim: [sequence_length]\n",
        "    seq_length = min_len\n",
        "\n",
        "    # predict\n",
        "    pred = forward_with_sigmoid(input_indices) #.item()\n",
        "    print(pred)\n",
        "    score = torch.max(pred).item()\n",
        "    print(score)\n",
        "    if score >= 0 and score < 0.2:\n",
        "      label = Label.vocab.stoi[\"very negative\"]\n",
        "    elif score >= 0.2 and score < 0.4:\n",
        "      label = Label.vocab.stoi[\"negative\"]\n",
        "    elif score >= 0.4 and score < 0.6:\n",
        "      label = Label.vocab.stoi[\"neutral\"]\n",
        "    elif score >=0.6 and score < 0.8:\n",
        "      label = Label.vocab.stoi[\"positive\"]\n",
        "    else:\n",
        "      label = Label.vocab.stoi[\"very positive\"]\n",
        "    pred_ind = label #round(pred)\n",
        "    #print(label)\n",
        "\n",
        "    # generate reference indices for each sample\n",
        "    reference_indices = token_reference.generate_reference(seq_length, device=device).unsqueeze(0)\n",
        "    #print(reference_indices)\n",
        "    #print(input_indices)\n",
        "\n",
        "    # compute attributions and approximation delta using layer integrated gradients\n",
        "    attributions_ig, delta = lig.attribute(input_indices, reference_indices, target=pred_ind, \\\n",
        "                                           n_steps=500, return_convergence_delta=True)\n",
        "    \n",
        "    #print(Label.vocab.itos[pred_ind])\n",
        "\n",
        "    print(f\"pred: {Label.vocab.itos[pred_ind]}, {label}, delta: {abs(delta)}\")\n",
        "\n",
        "    add_attributions_to_visualizer(attributions_ig, text, label, pred_ind, true_label, delta, vis_data_records_ig)\n",
        "    \n",
        "def add_attributions_to_visualizer(attributions, text, pred, pred_ind, label, delta, vis_data_records):\n",
        "    attributions = attributions.sum(dim=2).squeeze(0)\n",
        "    attributions = attributions / torch.norm(attributions)\n",
        "    attributions = attributions.cpu().detach().numpy()\n",
        "\n",
        "    # storing couple samples in an array for visualization purposes\n",
        "    vis_data_records.append(visualization.VisualizationDataRecord(\n",
        "                            attributions,\n",
        "                            pred,\n",
        "                            Label.vocab.itos[pred_ind],\n",
        "                            Label.vocab.itos[label],\n",
        "                            Label.vocab.itos[1],\n",
        "                            attributions.sum(),       \n",
        "                            text,\n",
        "                            delta))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61-gpGgASyso",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8237714c-f2fb-404e-ba8c-23308fd204f2"
      },
      "source": [
        "for key in Label.vocab.freqs:\n",
        "  print(key, Label.vocab.stoi[key])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "positive 0\n",
            "very positive 3\n",
            "neutral 2\n",
            "negative 1\n",
            "very negative 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jTjrO8LaUb8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "840766d0-4969-4f7c-b6bf-832eef87b1bb"
      },
      "source": [
        "interpret_sentence(model, 'It was a fantastic performance !', true_label=3)\n",
        "interpret_sentence(model, \"Renner 's performance as Dahmer is unforgettable , deeply absorbing .\", true_label=3)\n",
        "interpret_sentence(model, 'Best film ever', true_label=3)\n",
        "interpret_sentence(model, 'Too leisurely paced and visually drab for its own good , it succeeds in being only sporadically amusing .', true_label=2)\n",
        "interpret_sentence(model, 'It was a horrible movie', true_label=1)\n",
        "interpret_sentence(model, 'I\\'ve never watched something as bad', true_label=4)\n",
        "interpret_sentence(model, 'It is a disgusting movie!', true_label=4)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.6607, 0.2069, 0.5774, 0.7581, 0.1603]], device='cuda:0',\n",
            "       grad_fn=<SigmoidBackward>)\n",
            "0.7580726146697998\n",
            "pred: positive, 0, delta: tensor([0.0001], device='cuda:0', dtype=torch.float64)\n",
            "tensor([[0.8077, 0.1877, 0.3625, 0.7534, 0.1246]], device='cuda:0',\n",
            "       grad_fn=<SigmoidBackward>)\n",
            "0.8077468872070312\n",
            "pred: very positive, 3, delta: tensor([5.6122e-05], device='cuda:0', dtype=torch.float64)\n",
            "tensor([[0.6184, 0.1784, 0.3403, 0.9118, 0.1656]], device='cuda:0',\n",
            "       grad_fn=<SigmoidBackward>)\n",
            "0.911780059337616\n",
            "pred: very positive, 3, delta: tensor([0.0013], device='cuda:0', dtype=torch.float64)\n",
            "tensor([[0.4955, 0.5837, 0.4865, 0.3659, 0.3169]], device='cuda:0',\n",
            "       grad_fn=<SigmoidBackward>)\n",
            "0.5837150812149048\n",
            "pred: neutral, 2, delta: tensor([0.0004], device='cuda:0', dtype=torch.float64)\n",
            "tensor([[0.5237, 0.3832, 0.3331, 0.7205, 0.4246]], device='cuda:0',\n",
            "       grad_fn=<SigmoidBackward>)\n",
            "0.7205315828323364\n",
            "pred: positive, 0, delta: tensor([0.0004], device='cuda:0', dtype=torch.float64)\n",
            "tensor([[0.3860, 0.7135, 0.3652, 0.2191, 0.7001]], device='cuda:0',\n",
            "       grad_fn=<SigmoidBackward>)\n",
            "0.7134676575660706\n",
            "pred: positive, 0, delta: tensor([3.1352e-05], device='cuda:0', dtype=torch.float64)\n",
            "tensor([[0.6444, 0.3648, 0.4661, 0.6997, 0.3098]], device='cuda:0',\n",
            "       grad_fn=<SigmoidBackward>)\n",
            "0.6997070908546448\n",
            "pred: positive, 0, delta: tensor([0.0007], device='cuda:0', dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRjvGDn4acTQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "outputId": "10c527a3-5eae-4ffd-ce32-96d904d1e1a8"
      },
      "source": [
        "print('Visualize attributions based on Integrated Gradients')\n",
        "_ = visualization.visualize_text(vis_data_records_ig)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Visualize attributions based on Integrated Gradients\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>very positive</b></text></td><td><text style=\"padding-right:2em\"><b>positive (0.00)</b></text></td><td><text style=\"padding-right:2em\"><b>negative</b></text></td><td><text style=\"padding-right:2em\"><b>0.91</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> it                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> was                    </font></mark><mark style=\"background-color: hsl(120, 75%, 88%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(0, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> fantastic                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> performance                    </font></mark><mark style=\"background-color: hsl(120, 75%, 53%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> !                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>very positive</b></text></td><td><text style=\"padding-right:2em\"><b>very positive (3.00)</b></text></td><td><text style=\"padding-right:2em\"><b>negative</b></text></td><td><text style=\"padding-right:2em\"><b>0.14</b></text></td><td><mark style=\"background-color: hsl(120, 75%, 74%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> renner                    </font></mark><mark style=\"background-color: hsl(0, 75%, 86%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 's                    </font></mark><mark style=\"background-color: hsl(120, 75%, 87%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> performance                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> as                    </font></mark><mark style=\"background-color: hsl(0, 75%, 79%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> dahmer                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(0, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> unforgettable                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ,                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> deeply                    </font></mark><mark style=\"background-color: hsl(120, 75%, 86%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> absorbing                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> .                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>very positive</b></text></td><td><text style=\"padding-right:2em\"><b>very positive (3.00)</b></text></td><td><text style=\"padding-right:2em\"><b>negative</b></text></td><td><text style=\"padding-right:2em\"><b>1.08</b></text></td><td><mark style=\"background-color: hsl(120, 75%, 51%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> best                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> film                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ever                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>neutral</b></text></td><td><text style=\"padding-right:2em\"><b>neutral (2.00)</b></text></td><td><text style=\"padding-right:2em\"><b>negative</b></text></td><td><text style=\"padding-right:2em\"><b>0.50</b></text></td><td><mark style=\"background-color: hsl(120, 75%, 71%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> too                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> leisurely                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> paced                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> visually                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> drab                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> for                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> its                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> own                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> good                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ,                    </font></mark><mark style=\"background-color: hsl(0, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> it                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> succeeds                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(120, 75%, 73%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> being                    </font></mark><mark style=\"background-color: hsl(120, 75%, 79%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> only                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> sporadically                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> amusing                    </font></mark><mark style=\"background-color: hsl(0, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> .                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>negative</b></text></td><td><text style=\"padding-right:2em\"><b>positive (0.00)</b></text></td><td><text style=\"padding-right:2em\"><b>negative</b></text></td><td><text style=\"padding-right:2em\"><b>-0.45</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> it                    </font></mark><mark style=\"background-color: hsl(0, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> was                    </font></mark><mark style=\"background-color: hsl(120, 75%, 75%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(0, 75%, 68%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> horrible                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> movie                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>very negative</b></text></td><td><text style=\"padding-right:2em\"><b>positive (0.00)</b></text></td><td><text style=\"padding-right:2em\"><b>negative</b></text></td><td><text style=\"padding-right:2em\"><b>-0.75</b></text></td><td><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> i                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 've                    </font></mark><mark style=\"background-color: hsl(120, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> never                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> watched                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> something                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> as                    </font></mark><mark style=\"background-color: hsl(0, 75%, 62%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> bad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>very negative</b></text></td><td><text style=\"padding-right:2em\"><b>positive (0.00)</b></text></td><td><text style=\"padding-right:2em\"><b>negative</b></text></td><td><text style=\"padding-right:2em\"><b>0.96</b></text></td><td><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> it                    </font></mark><mark style=\"background-color: hsl(120, 75%, 76%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> disgusting                    </font></mark><mark style=\"background-color: hsl(0, 75%, 86%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> movie                    </font></mark><mark style=\"background-color: hsl(120, 75%, 63%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> !                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark></td><tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6DlhPVjZRQr"
      },
      "source": [
        "Captum visualization library shows in green tokens that push the prediction towards the target class. Those driving the score towards the reference value are marked in red. As a result, words perceived as positive will appear in green if attribution is performed against the predicted class but will be highlighted in red with an attribution targeting attributed label class.\n",
        "\n",
        "Because importance scores ar assigned to tokens, not words, some examples may show, that attribution is highly dependent on tokenization. Classification results may vary between runs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHG-rkdgZSR0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}